Course Overview
Hello, and welcome to this course!

In this course, you will explore transformers, model frameworks, such as PyTorrch and Hugging Face. You’ll begin this course with a general framework to optimize large language models (LLMs) and fine-tune generative AI models. 

Additionally, you’ll learn about parameter-efficient fine-tuning (PEFT), low-rank adaptation (LoRA), and quantized low-rank adaptation (QLoRA).

You’ll also practice hands-on labs such as loading, pretraining, fine-tuning, and applying models with Hugging Face and PyTorch. 

Prerequisites: 
You’ll require basic knowledge of Python, PyTorch, and neural networks. This course is suitable for professionals aspiring to build their careers in AI engineering, including training, developing, fine-tuning, and deploying LLMs. This specialization is suitable for existing and aspiring data scientists and machine learning engineers with basic knowledge of Python. 

Generative AI for Data Scientists Specialization:

Generative AI: Introduction and Applications

Generative AI: Prompt Engineering Basics

Generative AI: Elevate Your Data Science Career

Generative AI Engineering Specialization:

Course 1: Generative AI and LLMs: Architecture and Data Preparation

Course 2: Generative AI Foundational Models for NLP & Language Understanding
[CN1]

Course 3: Generative AI Language Modeling with Transformers

Course Objectives:
After completing this course, you will be able to:

Explore transformers, language model frameworks, and platforms, such as LangChain and Hugging Face

Demonstrate how to load models and their inferences, fine-tuning models with PyTorch and Hugging Face

Describe the concepts of parameter-efficient fine-tuning (PEFT) 

Explain the concepts of adaptors such as LoRA and QLoRA with Hugging Face and PyTorch

Course Outline:
This course consists of one module. We encourage you to set aside dedicated hours each week to complete this course successfully. Consistency will help you achieve your learning goals!

You will benefit from viewing all videos and readings and solidifying that knowledge by completing all activities.

This module provides an overview of Hugging Face and PyTorch frameworks in AI development and their differences. You’ll also learn to use pretrained transformer models and then fine-tune models using Hugging Face and PyTorch. Further, you’ll learn to prepare a dataset for loading and model definition and fine-tuning the complete model with its final layer. 

The hands-on lab in this module will provide practice on training a base model and pre-train LLMs with Hugging Face and PyTorch. 

Module 1: Transformers and Fine-Tuning

This module provides an overview of Hugging Face and PyTorch frameworks in AI development and their differences. You’ll also learn to use pretrained transformer models and then fine-tune models using Hugging Face and PyTorch. Further, you’ll learn to prepare a dataset for loading and model definition and fine-tuning the complete model with its final layer. 

The hands-on lab in this module will provide practice on training a base model and pre-train LLMs with Hugging Face and PyTorch. 

Module 2: Parameter Efficient Fine-Tuning (PEFT)

This module will give you insights into PEFT, its importance, types, and methods. You’ll explore concepts of soft prompts to generate relevant output. You’ll also explore adaptors such as LoRA and QLoRA. 

You’ll understand that the LoRA reduces trainable parameters by leveraging pretrained models with high-dimensional matrices. Further, you’ll explore the unique quantization techniques and methods of QLoRA. You’ll also explore model quantization and soft prompts. 

In hands-on labs, you will practice fine-tuning PEFT adaptors LoRA and QLoRA using PyTorch and Hugging Face.

Tools/Software Used: 
In this course, you can view videos and readings of the courses using any web-enabled device, including tablets and mobile phones. You require a modern web browser to complete this course. You’re provided access to a cloud-based environment to complete labs in this course. You could sign up for platforms such as Hugging Face and watsonx.ai and its functionalities.

Congratulations on taking these steps to further your knowledge and career! Enjoy your journey.