# C8M1.5. Document Catergorization Prediction with Torchtext

Last edited: February 15, 2025 1:50 AM
Tags: Course 08

Welcome to document categorization prediction with torch text. A document classifier seamlessly categorizes articles by analyzing the text content. As demonstrated, you simply feed in the raw text and the system efficiently outputs the document's classification, whether it's science and technology, sports, business, or any other class. After watching this video, you'll be able to explain what neural networks are and describe basic neural network hyperparameters. You'll also create a neural network in pytorch. First, let's do a quick recap of neural networks, where you'll mainly concentrate on understanding the inputs and outputs. A neural network is a mathematical function consisting of a sequence of matrix multiplications with a variety of other functions. It begins with an input layer. For instance, consider a bag of words vector. In this layer, you'll perform matrix multiplication, occasionally adding a bias. This constitutes the hidden layer if the input employs a bag of words. This layer is known as the embedding layer and its output is referred to as the logits. Subsequently, apply an activation function to each logit, a process known as activation where each element is called a neuron. Sometimes an activation function or bias addition is not applied to embedding layers. The operation is then repeated. Another matrix multiplication is performed and once again each resulting element is termed a neuron. Through this iterative process, the input data is transformed step by step, enabling the network to learn classification. The parameters that the network adjusts during training are known as learnable parameters. In the article, ESPNs varied football coverage input an embedding vector into the network. For each category, the neural network outputs a vector of logits where each logit is a score reflecting the article's likelihood of fitting a particular news category. As shown here, the associated table links vector elements to categories. World is first, followed by sports, business and science and technology. To determine the class of an article, you're going to input the logits from the output layer into the argmax function. The argmax function identifies the index of the highest logit value corresponding to the most likely class. Here, the argmax function selects index one, which has the highest logit value of seven. This indicates that the network classifies the article as belonging to the category associated with index one. This corresponds to the article class of sports. This graph illustrates the architecture of a neural network. Each circle represents a neuron starting from the left. Each neuron in the first box corresponds to an element in the input vector or input layer, and the connecting lines represent the weight matrix. The neurons at each subsequent level signify the components of the hidden and output layers. After processing through an activation function, obtain the hidden layer values, denoted as z. The final layer's connections embody the weights leading to the output, with each neuron reflecting one of the four output classes, world sports, business and science, and technology. After that, use argmax to find the class with the highest score. Now let's learn about the neural network hyperparameters. These are externally set configurations of a neural network. The architecture can vary in the number of hidden layers. For example, the network depicted at the top has a single hidden layer, while the one at the bottom features two hidden layers, with each feeding into the subsequent one. Don't forget that the input layer is just the input vector. Your focus will usually be on architectures with one hidden layer. You could adjust a number of neurons in each layer. For instance, in the network depicted above, the second hidden layer consists of five neurons, whereas the bottom network contains four. Furthermore, if the first hidden layer functions as an embedding layer, then the number of neurons corresponds to the vocabulary size. The number of neurons in the output layer always equals the number of classes. Both number layers and neurons can be selected via the empirical validation data. Now let's create a neural network in PyTorch. You will use the AG news data set using torch text. The output consists of text representing news articles along with their corresponding labels indicating their categories. You'll display the label and the news text in a table, then use a python dictionary to assign the appropriate category headlines to the labels. The news categories are displayed business for the first two sentences and science and technology for the last sentence. Let's build the standard text processing pipeline. You should tweak your functions so that label numbering begins at zero. Now you'll set up a batch function for embedding bags and add code to append the labels for each sample to a batch. Next, you'll create a data loader with a batch size of three. Let's explore the sample. Here you have three labels for each sample. Next are the token indices which form the basis for your bag of words model. Finally, observe the relative positions of these indices, which are essential for constructing the bag of words model. The model's architecture features two primary layers defined in the constructor. The first is the embedding bag layer, followed by the fully connected layer. The initialization of weights is also done during the forward pass. You'll input text and offset it into the embedding bag without applying the activation, which then feeds into the fully connected layer for the final output. Now create an instance of the text classification model with specified vocabulary size, vocab size, embedding dimension m size, and the number of output classes. Num class now make a prediction using the text indices and the offsets and assign it predicted label. First up, you're looking at the logic values in PyTorch, each row represents a different sample. Columns correspond to the logic values for each class. Unlike the earlier row vector example, it's organized by columns. Here, you'll then apply the argmax function across each row. This identifies the maximum value in each row. The position of this maximum value indicates the predicted class for samples 0, 1, and 2. The prediction function works on real text that starts by taking in tokenized text. It processes the text through the pipeline, and the model predicts the category. The label with the highest output value is then returned as the predicted category. When you apply the function, the article gets classified under sports. Trying this in the lab might yield a different result, since the model hasn't been trained yet. Let's now recap what you learned in this video, you learned that a document classifier seamlessly categorizes articles by analyzing the text content. A neural network is a mathematical function consisting of a sequence of matrix multiplications with a variety of other functions. The argmax function identifies the index of the highest logit value corresponding to the most likely class. Hyperparameters are externally set configurations of a neural network. The prediction function works on real text that starts by taking in tokenized text. It processes the text through the pipeline and the model predicts the category.